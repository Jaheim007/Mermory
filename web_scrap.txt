Avant de commencer mon scrap web je dois vérifier si les modules Beautiful soup et requests sont installés :
Exemple:(pip install bs4 , pip install requests)

Ensuite je les importe (depuis bs4 import BeautifulSoup et import requests)

Après je commence à inspecter le code html du site et je prends son url:

OU

Si j'ai déjà téléchargé le fichier html, il me suffit d'ouvrir le fichier:

Exemple:
        f = open("nom_du_ficher", "r")
        html_content = f.read() 
        f.close()
Après cette phase, j'ai utilisé (requests.get()) pour obtenir le source html du site.

Exemple:
    
source = requests.get(url).text
soup = BeautifulSoup(source, "lxml")

Pour terminer mon processus de Web scraping, j'inspecte les balises dont j'ai besoin sur le site Web et je les mets dans mon interface :

Exemple:
    
    price = soup.find('ul', class_='grid grid--uniform grid--view-items')
    prix = soup.find_all('li', class_ = 'grid__item grid__item--collection-template small--one-half medium-up--one-quarter')
    map = soup.find_all('div', class_ = 'price__regular')

FIN

